library("textprocessingDSI")
rcpp_join("~/test/", "~/joined.txt", 1)
pwd()
getwd9)
getwd()
rcpp_join("~/test/", "joined.txt", 1)
rcpp_join("./test/", "joined.txt", 1)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library("textprocessingDSI")
files = rcpp_join("/data/Water-Management/english-texts/", "/data/Water-Management/joined.txt", 1)
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE
comment = "#>"
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE
comment = "#>"
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE,
comment = "#>"
)
mylist = create_tt(x)
create_tt = function(x)
{
mylist = lapply(x, order)
return (mylist)
}
x = matrix(1:9, nrow = 3, ncol = 3)
mylist = create_tt(x)
mylist
x
mylist[[1]]
create_tt = function(x)
{
mylist = apply(x, order)
return (mylist)
}
x = matrix(1:9, nrow = 3, ncol = 3)
mylist = create_tt(x)
x = matrix(1:9, nrow = 3, ncol = 3)
x2 = apply(x, order)
x2 = apply(x, 1, order)
x2
x
x2 = apply(x, 1, sort)
x2
x
x2 = apply(x, 1, order)
x23
x2
x
order(x[1,])
order(x[2,])
source('~/test.R')
x
2x2
x2
x2 = apply(x, 2, order)
x2
x2 = apply(x, 1, order)
x2
x2[1]
x2[1,]
x2 = t(apply(x, 1, order))
x2
x
x =matrix(runif(5*2), ncol=5)
x2 = t(apply(x, 1, order))
x
x2
?order
x2 = t(apply(x, 1, order, decreasing=TRUE))
x2
x
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
scores
scores = x[indsorted]
source('~/test.R')
source('~/test.R')
scores
scores
source('~/test.R')
source('~/test.R')
library(JSONIO)
source('~/test.R')
install.packages("JSONIO")
library(jsonlite)
a = c(1, 2,3,4,5,56)
a
test = toJSON(a)
test
source('~/test.R')
vocab
class(vocab)
toJSON(vocab)
vocab[1,2,3]
vocab[,1,2,3]
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
create_tt = function(x, vocab)
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
}
vocab = c("one", "two", "three", "four", "five", "six")
x =matrix(runif(5*2), ncol=5)
scores = create_tt(x, vocab)
create_tt = function(x, vocab)
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
}
vocab = c("one", "two", "three", "four", "five", "six")
x =matrix(runif(5*2), ncol=5)
scores = create_tt(x, vocab)
source('~/test.R')
)
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
?paste
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
res
source('~/test.R')
res
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
x
source('~/test.R')
cat(res2)
source('~/test.R')
cat(res)
cat(res2)
source('~/test.R')
cat(res2)
source('~/test.R')
source('~/test.R')
cat(res)
cat(res2)
cat(res3)
source('~/test.R')
cat(res3)
knitr::opts_chunk$set(echo = TRUE)
library(ldaviewerDSI)
library(ldaviewerDSI)
?create_viewer
setwd("~/programs/ldaviewerDSI/vignettes")
knitr::opts_chunk$set(
collapse = TRUE,
eval = TRUE,
warning = FALSE,
comment = "#>"
)
library(tm) # for dtm
library(lda) # to run the lda model
library(topicmodels) # for dtm2ldaformat
library(ldaviewerDSI) # to create the viewer
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
fnames = list.files(idir, pattern="*.txt", full.names=FALSE)
head(fnames)
s = sample(1:length(fnames), 500)
fnames = fnames[s]
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus) #create dtm
dtm = tm::removeSparseTerms(dtm,.995) #remove sparse terms
inspect(dtm)
lda_input = topicmodels::dtm2ldaformat(dtm)
vocab = unlist(dtm$dimnames$Terms)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50)
texts = load_texts(paste(idir,fnames))
t = paste(idir,fnames)
t
texts = load_texts(paste(idir,fnames,sep="/"))
?create_viewer_json
json = create_viewer_json(tt, dt, vocab, fnames, texts, verbose=TRUE)
json = create_viewer_json(topic_terms, doc_topics, vocab, fnames, texts, verbose=TRUE)
doc_topics = t(apply(model$document_sums + 0.5, 2, function(x) x/sum(x)))
topic_terms = t(apply(t(model$topics) + 0.1, 2, function(x) x/sum(x)))
dim(doc_topics)
dim(topic_terms)
json = create_viewer_json(topic_terms, doc_topics, vocab, fnames, texts, verbose=TRUE)
?build_website
build_website(json, "./site", info="K=20 alpha=0.5 eta=0.1 burning=50 D=500 V=8004")
knitr::opts_chunk$set(
collapse = TRUE,
eval = TRUE,
warning = FALSE,
comment = "#>"
)
library(tm) # for dtm
library(lda) # to run the lda model
library(topicmodels) # for dtm2ldaformat
library(LDAvis) # to create the viewer
library(ldaviewerDSI) # to create the viewer
idir = system.file("extdata", "reviews/", package="ldaviewerDSI")
fnames = list.files(idir, pattern="*.txt", full.names=FALSE)
head(fnames)
s = sample(1:length(fnames), 500)
fnames = fnames[s]
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus) #create dtm
dtm = tm::removeSparseTerms(dtm,.995) #remove sparse terms
inspect(dtm)
lda_input = topicmodels::dtm2ldaformat(dtm)
vocab = unlist(dtm$dimnames$Terms)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50)
doc_topics = t(apply(model$document_sums + 0.5, 2, function(x) x/sum(x)))
topic_terms = t(apply(t(model$topics) + 0.1, 2, function(x) x/sum(x)))
doc_lengths = rowSums(as.matrix(dtm))
word_freqs = colSums(as.matrix(dtm))
ldavis = createJSON(topic_terms, doc_topics, doc_lengths, lda_input$vocab, word_freqs, reorder.topics=FALSE)
texts = load_texts(paste(idir,fnames,sep="/"))
json = create_viewer_json(topic_terms, doc_topics, vocab, fnames, texts, verbose=TRUE)
