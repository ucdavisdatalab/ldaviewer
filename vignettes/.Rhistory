library("textprocessingDSI")
rcpp_join("~/test/", "~/joined.txt", 1)
pwd()
getwd9)
getwd()
rcpp_join("~/test/", "joined.txt", 1)
rcpp_join("./test/", "joined.txt", 1)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library("textprocessingDSI")
files = rcpp_join("/data/Water-Management/english-texts/", "/data/Water-Management/joined.txt", 1)
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE
comment = "#>"
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE
comment = "#>"
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE,
comment = "#>"
)
mylist = create_tt(x)
create_tt = function(x)
{
mylist = lapply(x, order)
return (mylist)
}
x = matrix(1:9, nrow = 3, ncol = 3)
mylist = create_tt(x)
mylist
x
mylist[[1]]
create_tt = function(x)
{
mylist = apply(x, order)
return (mylist)
}
x = matrix(1:9, nrow = 3, ncol = 3)
mylist = create_tt(x)
x = matrix(1:9, nrow = 3, ncol = 3)
x2 = apply(x, order)
x2 = apply(x, 1, order)
x2
x
x2 = apply(x, 1, sort)
x2
x
x2 = apply(x, 1, order)
x23
x2
x
order(x[1,])
order(x[2,])
source('~/test.R')
x
2x2
x2
x2 = apply(x, 2, order)
x2
x2 = apply(x, 1, order)
x2
x2[1]
x2[1,]
x2 = t(apply(x, 1, order))
x2
x
x =matrix(runif(5*2), ncol=5)
x2 = t(apply(x, 1, order))
x
x2
?order
x2 = t(apply(x, 1, order, decreasing=TRUE))
x2
x
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
scores
scores = x[indsorted]
source('~/test.R')
source('~/test.R')
scores
scores
source('~/test.R')
source('~/test.R')
library(JSONIO)
source('~/test.R')
install.packages("JSONIO")
library(jsonlite)
a = c(1, 2,3,4,5,56)
a
test = toJSON(a)
test
source('~/test.R')
vocab
class(vocab)
toJSON(vocab)
vocab[1,2,3]
vocab[,1,2,3]
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
create_tt = function(x, vocab)
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
}
vocab = c("one", "two", "three", "four", "five", "six")
x =matrix(runif(5*2), ncol=5)
scores = create_tt(x, vocab)
create_tt = function(x, vocab)
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
}
vocab = c("one", "two", "three", "four", "five", "six")
x =matrix(runif(5*2), ncol=5)
scores = create_tt(x, vocab)
source('~/test.R')
)
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
?paste
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
res
source('~/test.R')
res
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
x
source('~/test.R')
cat(res2)
source('~/test.R')
cat(res)
cat(res2)
source('~/test.R')
cat(res2)
source('~/test.R')
source('~/test.R')
cat(res)
cat(res2)
cat(res3)
source('~/test.R')
cat(res3)
knitr::opts_chunk$set(echo = TRUE)
library(ldaviewerDSI)
library(ldaviewerDSI)
?create_viewer
setwd("~/programs/ldaviewerDSI/vignettes")
knitr::opts_chunk$set(
collapse = TRUE,
eval = TRUE,
comment = "#>"
)
knitr::opts_chunk$set(
collapse = TRUE,
eval = TRUE,
comment = "#>"
)
library(ldaviewerDSI)
library(tm) # for dtm
library(lda) # to run the lda model
library(ldaviewerDSI) # to create the viewer
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
file.names = list.files(idir, pattern="*.txt", full.names=TRUE)
head(file.names)
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
file.names = list.files(idir, pattern="*.txt", full.names=TRUE)
head(file.names)
library(tm) # for dtm
library(lda) # to run the lda model
library(ldaviewerDSI) # to create the viewer
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
file.names = list.files(idir, pattern="*.txt", full.names=TRUE)
head(file.names)
detach("package:ldaviewerDSI", unload=TRUE)
library("ldaviewerDSI", lib.loc="~/R/x86_64-redhat-linux-gnu-library/3.5")
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
file.names = list.files(idir, pattern="*.txt", full.names=TRUE)
head(file.names)
file.names
idir
detach("package:ldaviewerDSI", unload=TRUE)
library("ldaviewerDSI", lib.loc="~/R/x86_64-redhat-linux-gnu-library/3.5")
library(tm) # for dtm
library(lda) # to run the lda model
library(ldaviewerDSI) # to create the viewer
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
file.names = list.files(idir, pattern="*.txt", full.names=TRUE)
head(file.names)
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
fnames = list.files(idir, pattern="*.txt", full.names=FALSE)
head(fnames)
filecontents = lapply(paste(idir,fnames,sep="/"), readLines)
filecontents[1]
filecontents = lapply(paste(idir,fnames,sep="/"), readLines)
filecontents[1][1:200]
filecontents = lapply(paste(idir,fnames,sep="/"), readLines)
filecontents[1]
filecontents = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = Corpus(VectorSource(filecontents))
dtm = DocumentTermMatrix(corpus)
inspect(dtm)
library(tm) # for dtm
library(lda) # to run the lda model
library(topicmodels) # for dtm2ldaformat
library(ldaviewerDSI) # to create the viewer
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
fnames = list.files(idir, pattern="*.txt", full.names=FALSE)
head(fnames)
filecontents = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(filecontents))
dtm = tm::DocumentTermMatrix(corpus)
inspect(dtm)
lda_input = topicmodels::dtm2ldaformat(dtm)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=lda_input$vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50)
filecontents = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(filecontents))
dtm = tm::removePunctuation(dtm)
filecontents = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(filecontents))
dtm = tm::removePunctuation(corpus)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
filecontents = lapply(filecontents, removePunctutation)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
filecontents = lapply(filecontents, tm::removePunctuation)
corpus = tm::Corpus(tm::VectorSource(filecontents))
dtm = tm::removePunctuation(corpus)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
filecontents = lapply(filecontents, tm::removePunctuation)
corpus = tm::Corpus(tm::VectorSource(filecontents))
dtm = tm::DocumentTermMatrix(corpus)
inspect(dtm)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
filecontents = tm_map(filecontents, tm::removePunctuation) #remove punctuation
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus)
inspect(dtm)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::removeSparseTerms(dtm,.98)
dtm = tm::DocumentTermMatrix(corpus)
inspect(dtm)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::removeSparseTerms(dtm,.90)
dtm = tm::DocumentTermMatrix(corpus)
inspect(dtm)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::removeSparseTerms(dtm,.20)
dtm = tm::DocumentTermMatrix(corpus)
inspect(dtm)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus)
dtm = tm::removeSparseTerms(dtm,.98)
inspect(dtm)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus)
dtm = tm::removeSparseTerms(dtm,.99)
inspect(dtm)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus)
dtm = tm::removeSparseTerms(dtm,.90)
inspect(dtm)
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus)
dtm = tm::removeSparseTerms(dtm,.995)
inspect(dtm)
lda_input = topicmodels::dtm2ldaformat(dtm)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=lda_input$vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50)
s = sample(1:nrow(fnames), 500)
s = sample(1:length(fnames), 500)
fnames = fnames[s]
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus) #create dtm
dtm = tm::removeSparseTerms(dtm,.995) #remove sparse terms
inspect(dtm)
knitr::opts_chunk$set(
collapse = TRUE,
eval = TRUE,
comment = "#>"
)
library(tm) # for dtm
library(lda) # to run the lda model
library(topicmodels) # for dtm2ldaformat
library(ldaviewerDSI) # to create the viewer
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
fnames = list.files(idir, pattern="*.txt", full.names=FALSE)
head(fnames)
s = sample(1:length(fnames), 500)
fnames = fnames[s]
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus) #create dtm
dtm = tm::removeSparseTerms(dtm,.995) #remove sparse terms
inspect(dtm)
lda_input = topicmodels::dtm2ldaformat(dtm)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=lda_input$vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50)
lda_input = topicmodels::dtm2ldaformat(dtm)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=lda_input$vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50, trace=0)
lda_input = topicmodels::dtm2ldaformat(dtm)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=lda_input$vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50, trace=0L)
lda_input = topicmodels::dtm2ldaformat(dtm)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=lda_input$vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50)
doc_topics = t(apply(model$document_sums + 0.5, 2, function(x) x/sum(x)))
topic_terms = t(apply(model$topics + 0.1, 2, function(x) x/sum(x)))
doc_topics
head(doc_topics)
doc_topics = t(apply(model$document_sums + 0.5, 2, function(x) x/sum(x)))
topic_terms = t(apply(model$topics + 0.1, 2, function(x) x/sum(x)))
dim(doc_topics)
dim(topic_terms)
doc_topics = t(apply(model$document_sums + 0.5, 2, function(x) x/sum(x)))
topic_terms = t(apply(t(model$topics + 0.1, 2, function(x) x/sum(x))))
doc_topics = t(apply(model$document_sums + 0.5, 2, function(x) x/sum(x)))
topic_terms = t(apply(t(model$topics) + 0.1, 2, function(x) x/sum(x)))
dim(doc_topics)
dim(topic_terms)
lda_input$vocab
class(lda_input$documents)
fnames
library(LDAvis)
?createJSON
detach("package:ldaviewerDSI", unload=TRUE)
library("ldaviewerDSI", lib.loc="~/R/x86_64-redhat-linux-gnu-library/3.5")
knitr::opts_chunk$set(
collapse = TRUE,
eval = TRUE,
comment = "#>"
)
doc_lengths = rowSums(as.matrix(dtm))
word_freqs = colSums(as.matrix(dtm))
myjson = createJSON(topic_terms, doc_topics, doc_lengths, vocab, word_freqs, reorder.topics=FALSE)
doc_lengths = rowSums(as.matrix(dtm))
word_freqs = colSums(as.matrix(dtm))
myjson = createJSON(topic_terms, doc_topics, doc_lengths, vocab, word_freqs, reorder.topics=FALSE)
vocab
library(tm) # for dtm
library(lda) # to run the lda model
library(topicmodels) # for dtm2ldaformat
library(LDAvis) # to create the viewer
library(ldaviewerDSI) # to create the viewer
idir = system.file("extdata", "reviews", package="ldaviewerDSI")
fnames = list.files(idir, pattern="*.txt", full.names=FALSE)
head(fnames)
s = sample(1:length(fnames), 500)
fnames = fnames[s]
raw = lapply(paste(idir,fnames,sep="/"), readLines)
corpus = tm::Corpus(tm::VectorSource(raw))
corpus = tm_map(corpus, tm::removePunctuation) #remove punctuation
corpus = tm_map(corpus, tm::removeNumbers) #remove numbers
corpus = tm_map(corpus, tm::removeWords, tm::stopwords("english")) #remove stopwords
dtm = tm::DocumentTermMatrix(corpus) #create dtm
dtm = tm::removeSparseTerms(dtm,.995) #remove sparse terms
inspect(dtm)
doc_lengths = rowSums(as.matrix(dtm))
word_freqs = colSums(as.matrix(dtm))
myjson = createJSON(topic_terms, doc_topics, doc_lengths, vocab, word_freqs, reorder.topics=FALSE)
doc_lengths = rowSums(as.matrix(dtm))
word_freqs = colSums(as.matrix(dtm))
myjson = createJSON(topic_terms, doc_topics, doc_lengths, lda_input$vocab, word_freqs, reorder.topics=FALSE)
word_freqs
dim(word_freqs)
length(word_freqs)
length(vocab)
legnth(lda_input$vocab)
length(lda_input$vocab)
dim(dtm)
colSums(as.matrix(dtm))
lda_input$documents
str(dtm)
lda_input = topicmodels::dtm2ldaformat(dtm)
vocab = unlist(dtm$dimnames$Terms)
model = lda::lda.collapsed.gibbs.sampler(documents = lda_input$documents, K=20, vocab=vocab, num.iterations=1000, alpha=0.5, eta=0.1, burnin=50)
doc_topics = t(apply(model$document_sums + 0.5, 2, function(x) x/sum(x)))
topic_terms = t(apply(t(model$topics) + 0.1, 2, function(x) x/sum(x)))
doc_lengths = rowSums(as.matrix(dtm))
word_freqs = colSums(as.matrix(dtm))
myjson = createJSON(topic_terms, doc_topics, doc_lengths, lda_input$vocab, word_freqs, reorder.topics=FALSE)
myjson
str(myjson)
JSONIO(myjson)
library(JSONIO)
length(myjson)
head(myjson)
create_viewer(doc_topics, topic_terms, lda_input$vocab, fnames, idir, "./site/", ldavisJSON = myjson, verbose=TRUE)
idir = system.file("extdata", "reviews/", package="ldaviewerDSI")
fnames = list.files(idir, pattern="*.txt", full.names=FALSE)
head(fnames)
create_viewer(doc_topics, topic_terms, lda_input$vocab, fnames, idir, "./site/", ldavisJSON = myjson, verbose=TRUE)
?create_viewer
?create_viewer
create_viewer
help(create_viewer)
??create_viewr
??create_viewer
